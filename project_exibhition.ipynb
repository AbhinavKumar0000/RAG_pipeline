{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhinavKumar0000/RAG_pipeline/blob/main/project_exibhition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNpcSdMJNd1y"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install -U langchain-community\n",
        "!pip install unstructured\n",
        "!pip install langchain_google_genai\n",
        "!pip install gtts\n",
        "!pip install -q google-cloud-texttospeech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2ZWyPcn4Xbw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import time\n",
        "import faiss\n",
        "import pickle\n",
        "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredURLLoader, PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from dotenv import load_dotenv\n",
        "from google.generativeai import list_models, configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14VkTWllOQ3F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r28_x5E15N3c"
      },
      "outputs": [],
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
        "    raise EnvironmentError(\"GOOGLE_API_KEY not found in .env file\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "curCWjde7Nl2"
      },
      "outputs": [],
      "source": [
        "# Configure Google Generative AI\n",
        "configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o25IeXF37fGo"
      },
      "outputs": [],
      "source": [
        "# Check available models\n",
        "def check_available_models():\n",
        "    try:\n",
        "        available_models = [model.name for model in list_models() if \"generateContent\" in model.supported_generation_methods]\n",
        "        return available_models\n",
        "        available_models\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error checking models: {str(e)}\"\n",
        "    return available_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS34kflB5TNi"
      },
      "outputs": [],
      "source": [
        "# Initialize Gemini LLM and embeddings\n",
        "try:\n",
        "    available_models = check_available_models()\n",
        "    if \"models/gemini-1.5-flash\" not in available_models:\n",
        "        raise ValueError(\"Model gemini-1.5-flash not available. Available models: \" + \", \".join(available_models))\n",
        "    llm = GoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.9, max_output_tokens=1000)\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "except Exception as e:\n",
        "    raise Exception(f\"Failed to initialize Gemini: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgiImRuN5WH3"
      },
      "outputs": [],
      "source": [
        "# Function to process URLs and create FAISS index\n",
        "def process_inputs(url1, url2, pdf1, pdf2):\n",
        "    file_path = \"faiss_store_gemini.index\"\n",
        "    metadata_path = \"faiss_store_gemini_metadata.pkl\"\n",
        "\n",
        "    loaded_documents = []\n",
        "\n",
        "    # Load from URLs\n",
        "    urls = [url for url in [url1, url2] if url and url.strip()]\n",
        "    if urls:\n",
        "        try:\n",
        "            url_loader = UnstructuredURLLoader(urls=urls)\n",
        "            loaded_documents.extend(url_loader.load())\n",
        "        except Exception as e:\n",
        "            return f\"Error loading URLs: {str(e)}\"\n",
        "\n",
        "    # Load from PDFs\n",
        "    pdfs = [pdf for pdf in [pdf1, pdf2] if pdf is not None]\n",
        "    for pdf_file in pdfs:\n",
        "        try:\n",
        "            # PyPDFLoader needs a file path, which is available in the Gradio File object's 'name' attribute\n",
        "            pdf_loader = PyPDFLoader(pdf_file.name)\n",
        "            loaded_documents.extend(pdf_loader.load())\n",
        "        except Exception as e:\n",
        "            return f\"Error loading PDF {pdf_file.name}: {str(e)}\"\n",
        "\n",
        "    if not loaded_documents:\n",
        "        return \"Please provide at least one valid URL or PDF file.\"\n",
        "\n",
        "    try:\n",
        "        # Split data\n",
        "        status = \"Text Splitter...Started...\"\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            separators=['\\n\\n', '\\n', '.', ','],\n",
        "            chunk_size=1000\n",
        "        )\n",
        "        docs = text_splitter.split_documents(loaded_documents)\n",
        "        if not docs:\n",
        "            return \"No text could be extracted from the provided sources.\"\n",
        "\n",
        "        # Create embeddings and save to FAISS index\n",
        "        status = \"Embedding Vector Started Building...\"\n",
        "        vectorstore_gemini = FAISS.from_documents(docs, embeddings)\n",
        "        time.sleep(2)\n",
        "\n",
        "        # Save the FAISS index and metadata\n",
        "        faiss.write_index(vectorstore_gemini.index, file_path)\n",
        "        with open(metadata_path, \"wb\") as f:\n",
        "            pickle.dump({\n",
        "                \"docstore\": vectorstore_gemini.docstore,\n",
        "                \"index_to_docstore_id\": vectorstore_gemini.index_to_docstore_id\n",
        "            }, f)\n",
        "\n",
        "        return \"Vector Store is Ready. You can now ask questions.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred during processing: {str(e)}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcoBkfjO5Y73"
      },
      "outputs": [],
      "source": [
        "# Function to query the FAISS index\n",
        "def query_faiss(question):\n",
        "    file_path = \"faiss_store_gemini.index\"\n",
        "    metadata_path = \"faiss_store_gemini_metadata.pkl\"\n",
        "    if not question or not question.strip():\n",
        "        return \"Please enter a valid question.\", \"\"\n",
        "\n",
        "    if not os.path.exists(file_path) or not os.path.exists(metadata_path):\n",
        "        return \"No FAISS index found. Please process URLs first.\", \"\"\n",
        "\n",
        "    try:\n",
        "        # Load the FAISS index and metadata\n",
        "        index = faiss.read_index(file_path)\n",
        "        with open(metadata_path, \"rb\") as f:\n",
        "            metadata = pickle.load(f)\n",
        "\n",
        "        # Reconstruct the FAISS vectorstore\n",
        "        vectorstore = FAISS(\n",
        "            embedding_function=embeddings,\n",
        "            index=index,\n",
        "            docstore=metadata[\"docstore\"],\n",
        "            index_to_docstore_id=metadata[\"index_to_docstore_id\"]\n",
        "        )\n",
        "\n",
        "        # Query the vectorstore\n",
        "        chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())\n",
        "        result = chain({\"question\": question}, return_only_outputs=True)\n",
        "\n",
        "        answer = result[\"answer\"]\n",
        "        sources = result.get(\"sources\", \"\")\n",
        "        sources_output = \"Sources:\\n\" + \"\\n\".join(sources.split(\"\\n\")) if sources else \"No sources available.\"\n",
        "\n",
        "        return answer, sources_output\n",
        "    except Exception as e:\n",
        "        return f\"Error querying FAISS index: {str(e)}\", \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "3UTgjaqBRtzh",
        "outputId": "885ee785-5101-4b9d-d0a0-0b1a1952da80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please upload the credentials JSON file you downloaded from Google Cloud.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c94a4ee9-e30d-41d2-93ea-3421edbc5bbe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c94a4ee9-e30d-41d2-93ea-3421edbc5bbe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving project-exhibition-470717-8b8187723059.json to project-exhibition-470717-8b8187723059.json\n",
            "\n",
            "✅ 'project-exhibition-470717-8b8187723059.json' uploaded successfully.\n",
            "Authentication is now set. You can run the main application cell.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# --- IMPORTANT ---\n",
        "# This cell must be run in an environment like Google Colab or a Jupyter Notebook\n",
        "# that supports file uploads.\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "\n",
        "    # 1. Run this cell. It will prompt you to upload your credentials JSON file.\n",
        "    print(\"Please upload the credentials JSON file you downloaded from Google Cloud.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # 2. Get the name of the uploaded file and set the environment variable.\n",
        "    if uploaded:\n",
        "        file_name = next(iter(uploaded))\n",
        "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = file_name\n",
        "        print(f\"\\n✅ '{file_name}' uploaded successfully.\")\n",
        "        print(\"Authentication is now set. You can run the main application cell.\")\n",
        "    else:\n",
        "        print(\"\\nUpload canceled. Authentication was not set.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"This upload script is designed for Google Colab.\")\n",
        "    print(\"If you are running locally, you must set the 'GOOGLE_APPLICATION_CREDENTIALS' environment variable manually.\")\n",
        "    print('Example: export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/key.json\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc4Yagm7gAL5"
      },
      "outputs": [],
      "source": [
        "from google.cloud import texttospeech\n",
        "import uuid\n",
        "\n",
        "def speak_text(text):\n",
        "    if not text or not text.strip():\n",
        "        return None\n",
        "\n",
        "    # This function now relies on the GOOGLE_APPLICATION_CREDENTIALS environment\n",
        "    # variable being set by the setup script.\n",
        "    if \"GOOGLE_APPLICATION_CREDENTIALS\" not in os.environ:\n",
        "        print(\"ERROR: Google Cloud authentication is not configured.\")\n",
        "        print(\"Please run the 'Authentication Setup' cell and upload your JSON credentials file first.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # The client automatically finds and uses the credentials from the\n",
        "        # GOOGLE_APPLICATION_CREDENTIALS environment variable.\n",
        "        client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "        # Set the text input to be synthesized\n",
        "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
        "\n",
        "        # Build the voice request, selecting a high-quality female WaveNet voice\n",
        "        voice = texttospeech.VoiceSelectionParams(\n",
        "            language_code=\"en-US\",\n",
        "            name=\"en-US-Wavenet-F\"\n",
        "        )\n",
        "\n",
        "        # Select the type of audio file you want returned\n",
        "        audio_config = texttospeech.AudioConfig(\n",
        "            audio_encoding=texttospeech.AudioEncoding.MP3\n",
        "        )\n",
        "\n",
        "        # Perform the text-to-speech request\n",
        "        response = client.synthesize_speech(\n",
        "            input=synthesis_input, voice=voice, audio_config=audio_config\n",
        "        )\n",
        "\n",
        "        # Save the binary audio content to a temporary file\n",
        "        filename = f\"{uuid.uuid4()}.mp3\"\n",
        "        with open(filename, \"wb\") as out:\n",
        "            out.write(response.audio_content)\n",
        "\n",
        "        return filename\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred in Google TTS function: {e}\")\n",
        "        print(\"Please ensure the 'Cloud Text-to-Speech API' is enabled for your project in the Google Cloud Console.\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw99wxbS5bzJ",
        "outputId": "f5df43de-f988-485e-a40a-ebaa276337b7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://07daa6a036f85d204e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://07daa6a036f85d204e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# WebInsight Querry: Analyze Articles & Documents\")\n",
        "    gr.Markdown(\"Provide up to two URLs or two PDF files to create a searchable knowledge base, then ask questions about the content.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"## Step 1: Provide Content Sources\")\n",
        "            url1 = gr.Textbox(label=\"URL 1\", placeholder=\"Enter a valid news article URL\")\n",
        "            url2 = gr.Textbox(label=\"URL 2\", placeholder=\"Enter another valid URL (optional)\")\n",
        "            pdf1 = gr.File(label=\"Upload PDF 1\", file_types=['.pdf'])\n",
        "            pdf2 = gr.File(label=\"Upload PDF 2 (optional)\", file_types=['.pdf'])\n",
        "            process_button = gr.Button(\"Create Knowledge Base\", variant=\"primary\")\n",
        "            status_output = gr.Textbox(label=\"Status\", lines=2, interactive=False)\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"## Step 2: Ask a Question\")\n",
        "            question_input = gr.Textbox(label=\"Question\", placeholder=\"Ask a question about the content...\")\n",
        "            answer_output = gr.Textbox(label=\"Answer\", lines=8, interactive=False)\n",
        "            sources_output = gr.Textbox(label=\"Sources\", lines=3, interactive=False)\n",
        "\n",
        "            with gr.Row():\n",
        "                query_button = gr.Button(\"Submit Question\")\n",
        "                speak_button = gr.Button(\"Speak Answer\")\n",
        "\n",
        "            audio_output = gr.Audio(label=\"Spoken Answer\", autoplay=False)\n",
        "\n",
        "    # Connect components to functions\n",
        "    process_button.click(\n",
        "        fn=process_inputs,\n",
        "        inputs=[url1, url2, pdf1, pdf2],\n",
        "        outputs=status_output\n",
        "    )\n",
        "\n",
        "    query_button.click(\n",
        "        fn=query_faiss,\n",
        "        inputs=question_input,\n",
        "        outputs=[answer_output, sources_output]\n",
        "    )\n",
        "\n",
        "    speak_button.click(\n",
        "        fn=speak_text,\n",
        "        inputs=answer_output,\n",
        "        outputs=audio_output\n",
        "    )\n",
        "\n",
        "    question_input.submit(\n",
        "        fn=query_faiss,\n",
        "        inputs=question_input,\n",
        "        outputs=[answer_output, sources_output]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYNwjH+xmZe5S6jiY1G12z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}